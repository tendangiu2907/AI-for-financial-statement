import time
import os
import json
import cv2
# import re
# import torch
import numpy as np
import pandas as pd
import tensorflow as tf
# import supervision as sv
# import matplotlib.pyplot as plt
# import matplotlib.patches as patches
# from matplotlib.patches import Patch
from ultralytics import YOLO
from PIL import Image, ImageDraw, ImageFont
from paddleocr import PaddleOCR, draw_ocr
from pdf2image import convert_from_path
from google import genai
from google.genai import types
from unidecode import unidecode
from fuzzywuzzy import fuzz
from datetime import datetime
# import base64
# import tempfile

from core.config import MODEL_SIGNATURE_PATH, MODEL_TABLE_TITLE_PATH, DEVICE, POPPLER_PATH, financial_tables, model, EXTRACTED_FOLDER, financial_tables_general
from core.config import financial_tables, model, financial_tables_general
from core.config import api_keys
from utils import retry_api_call, dataframe_to_json, json_to_dataframe_table, json_to_dataframe_title


class TableDetectService:
    def __init__(self):
        print("TableDetectService: Kh·ªüi t·∫°o l√† load model...")
        self.ocr = PaddleOCR(lang="en")
        self.table_title_detection_model = YOLO(MODEL_TABLE_TITLE_PATH).to(DEVICE)
        self.signature_detection_model = YOLO(MODEL_SIGNATURE_PATH).to(DEVICE)
        self.detection_class_names = ["table", "table rotated"]
        self.structure_class_map = {
            k: v
            for v, k in enumerate(
                [
                    "table",
                    "table column",
                    "table row",
                    "table column header",
                    "table projected row header",
                    "table spanning cell",
                    "no object",
                ]
            )
        }
        self.structure_class_thresholds = {
            "table": 0.5,
            "table column": 0.5,
            "table row": 0.5,
            "table column header": 0.5,
            "table projected row header": 0.5,
            "table spanning cell": 0.5,
            "no object": 10,  # Gi√° tr·ªã cao ƒë·ªÉ lo·∫°i b·ªè "no object"
        }

    def detect_table(self, pdf_path, file_name_origin):
        """
        Flow x·ª≠ l√Ω file pdf nh∆∞ sau:
        - Chuy·ªÉn file pdf th√†nh danh s√°ch c√°c h√¨nh ·∫£nh
        - L·∫∑p qua t·ª´ng h√¨nh v√† x·ª≠ l√Ω nh∆∞ sau:
            + N·∫øu h√¨nh ƒë√≥ c√≥ ch·ª©a table:
                > S·ª≠ d·ª•ng model best_model_YOlO ƒë·ªÉ detect ra b·∫≥ng
        """
        recognized_titles_set = set()
        dfs_dict = {}

        images = self.pdf_to_images(pdf_path)  # Chuy·ªÉn pdf th√†nh h√¨nh ·∫£nh

        index_start = 0  # B·∫Øt ƒë·∫ßu t·ª´ ·∫£nh ƒë·∫ßu ti√™n
        while index_start < len(images):
            index_chuky = None  # Reset m·ªói l·∫ßn l·∫∑p
            for i in range(index_start, len(images)):
                selected_images = []
                image = images[i]
                print(f"======== B·∫ÆT ƒê·∫¶U X·ª¨ L√ù ·∫¢NH {i+1} ========")

                # Nh·∫≠n di·ªán b·∫£ng -> table-title
                print(f"==== Ki·ªÉm tra b·∫£ng trong ·∫£nh ====")
                nhandien_table = self.table_detection(image)

                if not nhandien_table:
                    print(f"==== ·∫¢nh kh√¥ng c√≥ b·∫£ng, chuy·ªÉn sang ·∫£nh ti·∫øp theo ====")
                    print(f"======== K·∫æT TH√öC X·ª¨ L√ù ·∫¢NH {i+1} NO_TABLE ========\n\n\n\n")
                    continue  # N·∫øu kh√¥ng c√≥ b·∫£ng, b·ªè qua ·∫£nh n√†y

                has_rotated_table = any(
                    self.detection_class_names[det[5]] == "table rotated"
                    for det in nhandien_table
                )
                
                # Ch·ªâ xoay ·∫£nh n·∫øu c√≥ b·∫£ng xoay
                image_to_process = (
                    self.table_rotation(image, nhandien_table) if has_rotated_table else image
                )

                print(f"==== Nh·∫≠n di·ªán title c·ªßa b·∫£ng ====")
                df_title, text_title = self.detect_and_extract_title(image_to_process)
                for api_key in api_keys:
                    json_title = retry_api_call(
                        self.generate_title,
                        model,
                        api_keys[api_key]["title"],
                        dataframe_to_json(df_title),
                        text_title)
                    if json_title:
                        break
                print("==== Ho√†n t·∫•t th·ª≠ API cho nh·∫≠n di·ªán title ====")
                # print("==== K·∫øt qu·∫£ title ====")
                # print(f"{json_title}")

                data_title = json_to_dataframe_title(json_title)  # K·∫øt qu·∫£ title c·ªßa b·∫£ng
                recognized_title = self.recognize_financial_table(
                    data_title, financial_tables_general, threshold=80
                )  # Nh·∫≠n di·ªán xem title c·ªßa b·∫£ng l√† g√¨ c√≥ ph√π h·ª£p v·ªõi 3 t√™n b·∫£ng d·ª± √°n ƒë·ªÅ ra kh√¥ng

                # N·∫øu nh·∫≠n di·ªán ƒë∆∞·ª£c title, th√™m v√†o danh s√°ch nh·∫≠n di·ªán
                if not (recognized_title):
                    print(f"==== Kh√¥ng t√¨m th·∫•y title trong ·∫£nh ====")
                    print(f"======== K√âT TH√öC X·ª¨ L√ù ·∫¢NH {i+1} NO_TITLE========\n\n\n\n")
                    # ƒê·ªÉ sleep ƒë·ªÉ gi√∫p model ngh·ªâ, b·ªã limit 1 ph√∫t kh√¥ng qu√° 2 l·∫ßn
                    # time.sleep(45)
                    continue

                print(f"==== Nh·∫≠n di·ªán ƒë∆∞·ª£c title c·ªßa ·∫£nh l√† : {recognized_title} ====")

                # T√¨m ·∫£nh ch·ªØ k√Ω ti·∫øp theo sau ·∫£nh title
                print(f"==== Nh·∫≠n di·ªán ch·ªØ k√≠ t·ª´ ·∫£nh ti·∫øp theo ====")
                for j in range(images.index(image), len(images)):
                    nhandien_chuky = images[j]
                    results_chuky = self.detect_signature(nhandien_chuky)
                    if results_chuky[0]:
                        for r in results_chuky:
                            for box in r.boxes:
                                x1, y1, x2, y2 = box.xyxy[0]  # L·∫•y t·ªça ƒë·ªô
                                # C·∫Øt ·∫£nh ch·ªØ k√Ω
                                cropped_img = self.crop_signature(nhandien_chuky, (x1, y1, x2, y2))                
                                # Nh·∫≠n di·ªán l·∫°i tr√™n ·∫£nh ƒë√£ c·∫Øt
                                new_results = self.detect_signature(cropped_img)
                                if new_results[0]:
                                    break
                            if new_results[0]:
                                break
                        if new_results[0]:
                                break
                    # L·∫•y danh s√°ch ·∫£nh t·ª´ title ƒë·∫øn ch·ªØ k√Ω
                if index_chuky:
                    selected_images.extend(images[images.index(image) : index_chuky + 1])

                print(f"==== Cho model gi·∫£i lao tr∆∞·ªõc khi nh·∫≠n di·ªán th√¥ng tin b·∫£ng ====")
                time.sleep(45)

                # V√≤ng l·∫∑p qua ·∫£nh t·ª´ title ƒë·∫øn ch·ªØ k√Ω ƒë·ªÉ tr√≠ch xu·∫•t b·∫£ng
                if selected_images:
                    print(f"==== Nh·∫≠n di·ªán th√¥ng tin c·ªßa b·∫£ng {recognized_title} ====")
                    pre_name_column = None
                    for img in selected_images:
                        processed_image = self.Process_Image(img)
                         # 2Ô∏è‚É£ Chuy·ªÉn ƒë·ªïi ·∫£nh sang CMYK v√† l·∫•y k√™nh K
                        _, _, _, black_channel = self.rgb_to_cmyk(processed_image)
                        # 3Ô∏è‚É£ ƒêi·ªÅu ch·ªânh ƒë·ªô s√°ng & ƒë·ªô t∆∞∆°ng ph·∫£n
                        processed_image = self.adjust_contrast(black_channel, alpha=2.0, beta=-50)
                        if processed_image is not None:
                            df_table, text_table = self.process_pdf_image(processed_image)
                            if not df_table.empty:
                                if (len(df_table) < 101) and (len(df_table.columns) < 10):
                                    token = 9000
                                elif (len(df_table) < 201) and (len(df_table.columns) < 10):
                                    token = 18000
                                else:
                                    token = 30000
                                if selected_images.index(img) ==0:
                                    response_schema=self.generate_json_schema(dataframe_to_json(df_table))
                                for api_key in api_keys:
                                    json_table = retry_api_call(
                                        self.generate_table,
                                        model,
                                        api_keys[api_key]["table"],
                                        dataframe_to_json(df_table),
                                        text_table,
                                        token,
                                        pre_name_column, response_schema)
                                    if json_table:
                                        break
                                print("==== Ho√†n t·∫•t th·ª≠ API cho nh·∫≠n di·ªán th√¥ng tin c·ªßa b·∫£ng ====")
                                # print(f"==== K·∫øt qu·∫£ th√¥ng tin c·ªßa b·∫£ng {recognized_title} ====")
                                # print(json_table)    

                                data_table = json_to_dataframe_table(json_table)

                                if selected_images.index(img) ==0:
                                    found = False  # Flag ƒë·ªÉ tho√°t c·∫£ hai v√≤ng l·∫∑p khi t√¨m th·∫•y k·∫øt qu·∫£
                                    recognized_title = "B·∫£ng c√¢n ƒë·ªëi k·∫ø to√°n"
                                    for column in data_table.columns:
                                        for value in data_table[column].dropna():
                                            value = self.normalize_text(value)
                                            if "luu chuyen" in value:
                                                recognized_title = "B√°o c√°o l∆∞u chuy·ªÉn ti·ªÅn t·ªá"
                                                found = True
                                                break  # Tho√°t kh·ªèi v√≤ng l·∫∑p gi√° tr·ªã trong c·ªôt
                                            elif "doanh thu ban hang" in value or "ban hang" in value:
                                                recognized_title = "B√°o c√°o KQHƒêKD"
                                                found = True
                                                break  # Tho√°t kh·ªèi v√≤ng l·∫∑p gi√° tr·ªã trong c·ªôt
                                        if found:
                                            break  # Tho√°t kh·ªèi v√≤ng l·∫∑p c·ªôt

                                recognized_titles_set.add(recognized_title)
                                # display(data_table)
                                if selected_images.index(img) == 0:
                                    pre_name_column = data_table.columns.tolist()
                                else:
                                    if len(data_table.columns) == len(pre_name_column):
                                        data_table.columns = pre_name_column
                                    else:
                                        data_table = data_table.reindex(
                                            columns=pre_name_column, fill_value=None
                                        )
                                if not data_table.empty:
                                    if recognized_title not in dfs_dict:
                                        dfs_dict[recognized_title] = data_table
                                    else:
                                        dfs_dict[recognized_title] = pd.concat(
                                            [dfs_dict[recognized_title], data_table],
                                            ignore_index=True,
                                        )
                        print(f"==== Cho model gi·∫£i lao tr∆∞·ªõc khi nh·∫≠n di·ªán b·∫£ng ti·∫øp theo ====")
                        # time.sleep(45)
                            
                    print(f"==== Ho√†n t·∫•t nh·∫≠n di·ªán th√¥ng tin b·∫£ng {recognized_title} ====")
                    print(f"======== K√âT TH√öC X·ª¨ L√ù ·∫¢NH {i+1} SUCCESS========\n\n\n\n")
                break # beak ƒë·ªÉ c·∫≠p nh·∫≠t l·∫°i v√≠ tr√≠ b·∫Øt ƒë·∫ßu l√† v·ªã tr√≠ k·∫ø ti·∫øp c·ªßa ·∫£nh c√≥ ch·ªØ k√≠
               
            # C·∫≠p nh·∫≠t v·ªã tr√≠ b·∫Øt ƒë·∫ßu cho v√≤ng l·∫∑p ti·∫øp theo
            if index_chuky:
                index_start = index_chuky + 1
            else:
                index_start = i + 1
                # Ki·ªÉm tra n·∫øu ƒë√£ nh·∫≠n di·ªán ƒë·ªß b·∫£ng t√†i ch√≠nh th√¨ d·ª´ng
            if len(recognized_titles_set) == len(financial_tables):
                print("======== ƒê√É NH·∫¨N DI·ªÜN ƒê·ª¶ T·∫§T C·∫¢ C√ÅC B·∫¢NG T√ÄI CH√çNH. D·ª™NG L·∫†I !! ========\n\n\n\n")
                break

        # L∆∞u k·∫øt qu·∫£ v√†o file Excel
        print(f"======== B·∫§T ƒê·∫¶U L∆ØU D·ªÆ LI·ªÜU V√ÄO FILE ========")
        name, _ = file_name_origin.rsplit(".", 1) if "." in file_name_origin else (file_name_origin, "")
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")  # ƒê·ªãnh d·∫°ng th·ªùi gian: YYYYMMDD_HHMMSS
        new_name = f"{name}_{timestamp}.xlsx"
        file_path = os.path.join(EXTRACTED_FOLDER, new_name)
        with pd.ExcelWriter(file_path, engine="xlsxwriter") as writer: # TODO: No module named 'xlsxwriter'
            for i, (sheet_name, df) in enumerate(dfs_dict.items()):
                df.to_excel(writer, sheet_name=sheet_name[:31], index=False)
                print(f"==== ƒê√£ ghi xong b·∫£ng {sheet_name[:31]} v√†o file ====")
        print(f"======== D·ªÆ LI·ªÜU ƒê√É ƒê∆Ø·ª¢C L∆ØU V√ÄO {file_path} ========")
        download_url = f"/{EXTRACTED_FOLDER}/{new_name}"
        return dfs_dict, download_url            
    
    def rgb_to_cmyk(self,image):
        """ Chuy·ªÉn ƒë·ªïi ·∫£nh t·ª´ RGB sang kh√¥ng gian m√†u CMYK """
        if isinstance(image, Image.Image):
            image = np.array(image, dtype=np.uint8)
        b, g, r = cv2.split(image)
        # Chuy·ªÉn gi√° tr·ªã pixel v·ªÅ kho·∫£ng [0,1]
        r = r / 255.0
        g = g / 255.0
        b = b / 255.0

        # T√≠nh to√°n k√™nh K (ƒëen)
        k = 1 - np.max([r, g, b], axis=0)

        # Tr√°nh chia cho 0
        c = (1 - r - k) / (1 - k + 1e-10)
        m = (1 - g - k) / (1 - k + 1e-10)
        y = (1 - b - k) / (1 - k + 1e-10)

        # ƒê∆∞a v·ªÅ kho·∫£ng gi√° tr·ªã 0-255
        c = (c * 255).astype(np.uint8)
        m = (m * 255).astype(np.uint8)
        y = (y * 255).astype(np.uint8)
        k = (k * 255).astype(np.uint8)

        return c, m, y, k

    def adjust_contrast(self,image, alpha=2.0, beta=-50):
        """ ƒêi·ªÅu ch·ªânh ƒë·ªô t∆∞∆°ng ph·∫£n v√† ƒë·ªô s√°ng """
        adjusted = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)
        return adjusted
    def rgb_to_cmyk(self,image):
        """ Chuy·ªÉn ƒë·ªïi ·∫£nh t·ª´ RGB sang kh√¥ng gian m√†u CMYK """
        if isinstance(image, Image.Image):
            image = np.array(image, dtype=np.uint8)
        b, g, r = cv2.split(image)
        # Chuy·ªÉn gi√° tr·ªã pixel v·ªÅ kho·∫£ng [0,1]
        r = r / 255.0
        g = g / 255.0
        b = b / 255.0

        # T√≠nh to√°n k√™nh K (ƒëen)
        k = 1 - np.max([r, g, b], axis=0)

        # Tr√°nh chia cho 0
        c = (1 - r - k) / (1 - k + 1e-10)
        m = (1 - g - k) / (1 - k + 1e-10)
        y = (1 - b - k) / (1 - k + 1e-10)

        # ƒê∆∞a v·ªÅ kho·∫£ng gi√° tr·ªã 0-255
        c = (c * 255).astype(np.uint8)
        m = (m * 255).astype(np.uint8)
        y = (y * 255).astype(np.uint8)
        k = (k * 255).astype(np.uint8)

        return c, m, y, k

    def adjust_contrast(self,image, alpha=2.0, beta=-50):
        """ ƒêi·ªÅu ch·ªânh ƒë·ªô t∆∞∆°ng ph·∫£n v√† ƒë·ªô s√°ng """
        adjusted = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)
        return adjusted
    def pdf_to_images(self, pdf_path):
        images = convert_from_path(pdf_path, poppler_path=POPPLER_PATH)
        return images

    # model table_title_detection_model
    def table_detection(self, image):
        imgsz = 800
        pred = self.table_title_detection_model.predict(image, imgsz=imgsz)
        pred = pred[0].boxes
        result = pred.cpu().numpy()
        result_list = [
            list(result.xywhn[i]) + [result.conf[i], int(result.cls[i])]
            for i in range(result.shape[0])
        ]
        return result_list

    def table_rotation(self, image, list_detection_table):
        for det in list_detection_table:
            x_center, y_center, w_n, h_n, conf, cls_id = det
            if self.detection_class_names[cls_id] == "table rotated":
                print("This is a rotated table")
                image = image.rotate(-90, expand=True)
            img = image.convert("L")
            thresh_img = img.point(lambda p: 255 if p > 120 else 0)
            return thresh_img

    # model table_title_detection_model
    def Process_Image(self, image):
        results = self.table_title_detection_model.predict(image, task="detect")
        boxes = results[0].boxes

        for box in boxes:
            x1, y1, x2, y2 = box.xyxy[0].tolist()
            cls_id = int(box.cls[0])
            class_name = self.table_title_detection_model.names[cls_id]

            # Chuy·ªÉn ƒë·ªïi sang PIL n·∫øu c·∫ßn
            if isinstance(image, np.ndarray):
                image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))

            # C·∫Øt ·∫£nh tr∆∞·ªõc
            cropped_table = image.crop((int(x1), int(y1), int(x2), int(y2)))

            # plt.imshow(cropped_table)
            # plt.title("Cropped Image")
            # plt.show()

            # N·∫øu l√† b·∫£ng b·ªã xoay, xoay l·∫°i
            if class_name == "table rotated":
                print("This is a rotated table")
                cropped_img = cropped_table.rotate(-90, expand=True)
                return cropped_img  # Tr·∫£ v·ªÅ ·∫£nh ƒë√£ c·∫Øt v√† s·ª≠a g√≥c

            return cropped_table  # N·∫øu kh√¥ng b·ªã xoay, tr·∫£ v·ªÅ ·∫£nh c·∫Øt nguy√™n b·∫£n

    # s·ª≠ d·ª•ng model t·ª´ models = ["gemini-2.0-pro-exp-02-05", "gemini-2.0-flash-thinking-exp-01-21"]
    # chuy·ªÉn API key sang file config
    def generate_title(self, model, API, path_title_json, text_title):
        result = ""
        client = genai.Client(api_key=f"{API}")

        # M·ªü file JSON v√† ƒë·ªçc n·ªôi dung
        file_path = path_title_json
        with open(file_path, "r", encoding="utf-8") as f:
            json_content = json.load(f)  # Load JSON th√†nh dict

        model = model
        contents = [
            types.Content(
                role="user",
                parts=[
                    types.Part.from_text(
                        text=f"""M√¨nh ƒëang tr√≠ch xu·∫•t d·ªØ li·ªáu t·ª´ h√¨nh ·∫£nh ch·ª©a b·∫£ng t√†i ch√≠nh b·∫±ng PaddleOCR. D·ªØ li·ªáu nh·∫≠n di·ªán ƒë∆∞·ª£c l∆∞u trong {text_title}.
    Tuy nhi√™n, d·ªØ li·ªáu g·∫∑p l·ªói:
    - Sai ch√≠nh t·∫£ ti·∫øng Vi·ªát trong b√°o c√°o t√†i ch√≠nh, k·∫ø to√°n v√† d√≤ng ti·ªÅn
    - L·ªói ng·ªØ ph√°p ti·∫øng Vi·ªát trong b√°o c√°o t√†i ch√≠nh, k·∫ø to√°n v√† d√≤ng ti·ªÅn
    V√¨ ƒë√¢y l√† m·ªôt b√°o c√°o quan tr·ªçng, r·∫•t nhi·ªÅu th·ª© ·∫£nh h∆∞·ªüng x·∫•u ƒë·∫øn n·∫øu nh∆∞ n√≥ sai ch√≠nh t·∫£ v√† l·ªói ng·ªØ ph√°p.
    B·∫°n h√£y tr·∫£ v·ªÅ cho m√¨nh m·ªôt DataFrame ch·ªâ c√≥ 1 c·ªôt l√† "values" ch·ª©a c√°c gi√° tr·ªã ƒë∆∞·ª£c ngƒÉn c√°ch th√†nh t·ª´ng d√≤ng gi√∫p ng∆∞·ªùi ƒë·ªçc d·ªÖ d√†ng ƒë·ªçc hi√™u, m·ªói h√†ng kh√¥ng ch·ª©a l·ªìng gh√©p th√†nh chu·ªói hay danh s√°ch g√¨, ch·ªâ 1 d√≤ng l√† 1 gi√° tr·ªã ri√™ng bi·ªát t·ª´ file JSON g·ªëc.
                        D·ªØ li·ªáu JSON g·ªëc:
                        {json.dumps(json_content, indent=2, ensure_ascii=False)}
                        """
                    ),
                ],
            ),
        ]

        generate_content_config = types.GenerateContentConfig(
            max_output_tokens=8192,
            response_mime_type="application/json")

        for chunk in client.models.generate_content_stream(
            model=model,
            contents=contents,
            config=generate_content_config,
        ):
            result += chunk.text
        return result
    def generate_json_schema(self, json_file_path):
        """T·∫°o JSON Schema t·ª´ file JSON ƒë·∫ßu v√†o."""

        try:
            with open(json_file_path, 'r', encoding='utf-8') as f:
                json_data = json.load(f)
        except FileNotFoundError:
            print(f"L·ªói: Kh√¥ng t√¨m th·∫•y file JSON t·∫°i '{json_file_path}'")
            return
        except json.JSONDecodeError:
            print(f"L·ªói: File '{json_file_path}' kh√¥ng ph·∫£i l√† JSON h·ª£p l·ªá.")
            return

        json_string = json.dumps(json_data, ensure_ascii=False)

        client = genai.Client(api_key="AIzaSyAVa_jH5PG6UnOIpTD0MQztdI4QEPIKs5Y")
        model = "gemini-2.0-flash"

        prompt = f"""
        H√£y t·∫°o m·ªôt JSON Schema t·ª´ d·ªØ li·ªáu JSON sau ƒë√¢y:

        {json_string}

        Y√™u c·∫ßu:
        1. T·∫°o m·ªôt JSON Schema h·ª£p l·ªá ƒë·ªÉ m√¥ t·∫£ c·∫•u tr√∫c d·ªØ li·ªáu JSON.
        2. S·ª≠ d·ª•ng c√°c ki·ªÉu d·ªØ li·ªáu JSON Schema ph√π h·ª£p cho t·ª´ng thu·ªôc t√≠nh.
        3. N·∫øu c√≥ th·ªÉ, h√£y suy ra c√°c r√†ng bu·ªôc (constraints) t·ª´ d·ªØ li·ªáu (v√≠ d·ª•: required, nullable).
        4. T·∫°o m·ªôt schema t·ªïng qu√°t, c√≥ th·ªÉ x·ª≠ l√Ω c√°c JSON c√≥ c·∫•u tr√∫c kh√°c nhau.
        5. Tr·∫£ v·ªÅ k·∫øt qu·∫£ l√† m·ªôt chu·ªói JSON Schema h·ª£p l·ªá.
        """

        contents = [
            types.Content(
                role="user",
                parts=[types.Part.from_text(text=prompt)],
            ),
        ]

        generate_content_config = types.GenerateContentConfig(
            response_mime_type="application/json",
        )

        response_text = ""
        for chunk in client.models.generate_content_stream(
            model=model,
            contents=contents,
            config=generate_content_config,
        ):
            response_text += chunk.text

        try:
            # Ki·ªÉm tra v√† in JSON Schema h·ª£p l·ªá
            json.loads(response_text)
        except json.JSONDecodeError:
            print("L·ªói: K·∫øt qu·∫£ kh√¥ng ph·∫£i l√† JSON h·ª£p l·ªá.")
            print("K·∫øt qu·∫£ t·ª´ Gemini:")

    def generate_table(self, model, API, path_dataframe_json, text_table, token, table_columns, response_schema):
        """T·∫°o b·∫£ng d·ªØ li·ªáu t·ª´ JSON ƒë·∫ßu v√†o, s·ª≠ d·ª•ng JSON Schema tr·∫£ v·ªÅ."""

        result = ""

        # Kh·ªüi t·∫°o API Client
        client = genai.Client(api_key=API)

        # M·ªü file JSON v√† ƒë·ªçc n·ªôi dung
        with open(path_dataframe_json, "r", encoding="utf-8") as f:
            json_content = json.load(f)

        # Prompt c·∫£i ti·∫øn
        prompt_text = f"""
        M√¨nh ƒëang x·ª≠ l√Ω d·ªØ li·ªáu t·ª´ h√¨nh ·∫£nh ch·ª©a b·∫£ng t√†i ch√≠nh, tr√≠ch xu·∫•t b·∫±ng PaddleOCR.
        D·ªØ li·ªáu nh·∫≠n di·ªán ƒë∆∞·ª£c l∆∞u trong {text_table}, nh∆∞ng g·∫∑p l·ªói sai ch√≠nh t·∫£, ng·ªØ ph√°p, v√† c·∫•u tr√∫c b·∫£ng.

        D·ª±a v√†o b·ªë c·ª•c v√† n·ªôi dung JSON g·ªëc, b·∫°n h√£y:
        - S·ª≠a l·ªói ch√≠nh t·∫£, ng·ªØ ph√°p ti·∫øng Vi·ªát.
        - S·∫Øp x·∫øp l·∫°i d·ªØ li·ªáu ƒë·ªÉ ƒë·∫£m b·∫£o ƒë√∫ng th·ª© t·ª± d√≤ng/c·ªôt theo chu·∫©n b√°o c√°o t√†i ch√≠nh.
        - ƒê·∫∑t t√™n c·ªôt ƒë√∫ng chu·∫©n. N·∫øu danh s√°ch {table_columns} r·ªóng, ƒë·∫∑t m·∫∑c ƒë·ªãnh g·ªìm "M√£ s·ªë", "T√™n ch·ªâ ti√™u", "Thuy·∫øt minh".
        - Chu·∫©n h√≥a d·ªØ li·ªáu s·ªë (ƒë·ªãnh d·∫°ng s·ªë nguy√™n/th·∫≠p ph√¢n, ƒë∆°n v·ªã ti·ªÅn t·ªá).
        - ƒê·ªãnh d·∫°ng c√°c c·ªôt s·ªë theo t√™n ch·ªâ ti√™u (v√≠ d·ª•: kho·∫£n chi ph√≠ hi·ªÉn th·ªã trong d·∫•u '()' ho·∫∑c '-').
        - Nh·∫≠n di·ªán kho·∫£ng th·ªùi gian t√†i ch√≠nh v√† ƒë·∫∑t t√™n c·ªôt s·ªë li·ªáu theo th·ªùi gian ƒë∆∞·ª£c nh·∫≠n di·ªán (V√≠ d·ª• "NƒÉm 2022", "NƒÉm 2023").

        V√≠ d·ª• v·ªÅ JSON ƒë·∫ßu ra mong mu·ªën:
        {{
            "dataframe": [
                {{
                    "M√£ s·ªë": "123",
                    "T√™n ch·ªâ ti√™u": "Doanh thu b√°n h√†ng",
                    "Thuy·∫øt minh": "Doanh thu t·ª´ ho·∫°t ƒë·ªông b√°n h√†ng",
                    "NƒÉm 2022": 1000000,
                    "NƒÉm 2023": 1200000
                }},
                {{
                    "M√£ s·ªë": "456",
                    "T√™n ch·ªâ ti√™u": "Chi ph√≠ qu·∫£n l√Ω",
                    "Thuy·∫øt minh": "Chi ph√≠ qu·∫£n l√Ω doanh nghi·ªáp",
                    "NƒÉm 2022": -200000,
                    "NƒÉm 2023": -250000
                }}
            ]
        }}

        D·ªØ li·ªáu JSON g·ªëc:
        {json.dumps(json_content, indent=2, ensure_ascii=False)}
        """

        # C·∫•u h√¨nh request ƒë·∫øn API
        contents = [
            types.Content(role="user", parts=[types.Part.from_text(text=prompt_text)])
        ]

        generate_content_config = types.GenerateContentConfig(
            max_output_tokens=token,
            response_mime_type="application/json",
            response_schema=response_schema  # S·ª≠ d·ª•ng schema truy·ªÅn v√†o
        )

        # G·ª≠i y√™u c·∫ßu v√† nh·∫≠n k·∫øt qu·∫£
        for chunk in client.models.generate_content_stream(
            model=model,
            contents=contents,
            config=generate_content_config,
        ):
            result += chunk.text

        return result

    def process_image_ocr(self, image):
        """Nh·∫≠n di·ªán text trong ·∫£nh b·∫±ng OCR."""
        if isinstance(image, Image.Image):
            image = np.array(image)
        output = self.ocr.ocr(image)[0]
        boxes = [line[0] for line in output]
        texts = [line[1][0] for line in output]
        probabilities = [line[1][1] for line in output]
        return image, boxes, texts, probabilities

    def get_horizontal_vertical_boxes(self, image, boxes):
        """T·∫°o danh s√°ch c√°c bounding box ngang v√† d·ªçc."""
        image_height, image_width = image.shape[:2]
        horiz_boxes = []
        vert_boxes = []

        for box in boxes:
            x_h, x_v = 0, int(box[0][0])
            y_h, y_v = int(box[0][1]), 0
            width_h, width_v = image_width, int(box[2][0] - box[0][0])
            height_h, height_v = int(box[2][1] - box[0][1]), image_height

            horiz_boxes.append([x_h, y_h, x_h + width_h, y_h + height_h])
            vert_boxes.append([x_v, y_v, x_v + width_v, y_v + height_v])

        return horiz_boxes, vert_boxes

    def apply_non_max_suppression(self, boxes, scores, image):
        """√Åp d·ª•ng Non-Max Suppression (NMS) ƒë·ªÉ lo·∫°i b·ªè c√°c bounding box d∆∞ th·ª´a."""
        nms_indices = tf.image.non_max_suppression(
            boxes,
            scores,
            max_output_size=1000,
            iou_threshold=0.1,
            score_threshold=float("-inf"),
        ).numpy()
        return np.sort(nms_indices)

    def intersection(self, box_1, box_2):
        """T√≠nh to√°n giao gi·ªØa hai bbox."""
        return [box_2[0], box_1[1], box_2[2], box_1[3]]

    def iou(self, box_1, box_2):
        """T√≠nh ch·ªâ s·ªë Intersection over Union (IoU)."""
        x_1, y_1 = max(box_1[0], box_2[0]), max(box_1[1], box_2[1])
        x_2, y_2 = min(box_1[2], box_2[2]), min(box_1[3], box_2[3])
        inter = abs(max((x_2 - x_1, 0)) * max((y_2 - y_1), 0))

        if inter == 0:
            return 0
        box_1_area = abs((box_1[2] - box_1[0]) * (box_1[3] - box_1[1]))
        box_2_area = abs((box_2[2] - box_2[0]) * (box_2[3] - box_2[1]))

        return inter / float(box_1_area + box_2_area - inter)

    def extract_table_data(self, boxes, texts, horiz_lines, vert_lines, horiz_boxes, vert_boxes):
        """Tr√≠ch xu·∫•t d·ªØ li·ªáu b·∫£ng t·ª´ bbox ƒë√£ nh·∫≠n di·ªán."""
        out_array = [["" for _ in range(len(vert_lines))] for _ in range(len(horiz_lines))]

        unordered_boxes = [vert_boxes[i][0] for i in vert_lines]
        ordered_boxes = np.argsort(unordered_boxes)

        for i in range(len(horiz_lines)):
            for j in range(len(vert_lines)):
                resultant = self.intersection(
                    horiz_boxes[horiz_lines[i]], vert_boxes[vert_lines[ordered_boxes[j]]]
                )
                for b, box in enumerate(boxes):
                    the_box = [box[0][0], box[0][1], box[2][0], box[2][1]]
                    if self.iou(resultant, the_box) > 0.1:
                        out_array[i][j] = texts[b]

        return pd.DataFrame(np.array(out_array))

    def process_pdf_image(self, image):
        """H√†m t·ªïng h·ª£p ƒë·ªÉ x·ª≠ l√Ω ·∫£nh t·ª´ PDF, nh·∫≠n di·ªán b·∫£ng v√† tr√≠ch xu·∫•t d·ªØ li·ªáu."""
        # OCR tr√≠ch xu·∫•t text & bbox
        image, boxes, texts, probabilities = self.process_image_ocr(image)

        # Nh·∫≠n di·ªán box ngang & d·ªçc
        horiz_boxes, vert_boxes = self.get_horizontal_vertical_boxes(image, boxes)

        # Lo·∫°i b·ªè c√°c box d∆∞ th·ª´a b·∫±ng Non-Max Suppression
        horiz_lines = self.apply_non_max_suppression(horiz_boxes, probabilities, image)
        vert_lines = self.apply_non_max_suppression(vert_boxes, probabilities, image)

        # Tr√≠ch xu·∫•t d·ªØ li·ªáu b·∫£ng th√†nh DataFrame
        df = self.extract_table_data(
            boxes, texts, horiz_lines, vert_lines, horiz_boxes, vert_boxes
        )

        return df, texts

    # model nh·∫≠n di·ªán ch·ªØ k√≠
    def detect_signature(self, image):
        return self.signature_detection_model(image)

    def crop_signature(self, image, bbox, margin=10):
        x1, y1, x2, y2 = map(int, bbox[:4])
        x1, y1, x2, y2 = x1 - margin, y1 - margin, x2 + margin, y2 + margin  # Th√™m margin
        return image.crop((max(x1, 0), max(y1, 0), min(x2, image.width), min(y2, image.height)))

    # model nh·∫≠n di·ªán table title
    def detect_and_extract_title(self, image):

        if isinstance(image, np.ndarray):
            image = Image.fromarray(image.astype(np.uint8))

        
        # Nh·∫≠n di·ªán table trong ·∫£nh ƒë·ªÉ c·∫Øt ph·∫ßn title
        results = self.table_title_detection_model(image)

        # L·∫•y ·∫£nh g·ªëc
        img_last = results[0].orig_img.copy()

        # L·∫•y danh s√°ch t·ªça ƒë·ªô ch·ªØ k√Ω (x1, y1, x2, y2)
        boxes_obj = results[0].boxes
        if boxes_obj is not None and len(boxes_obj) > 0:
            coords = boxes_obj.xyxy.cpu().numpy()  # Chuy·ªÉn v·ªÅ numpy array
            x1, y1, x2, y2 = map(int, coords[0])  # L·∫•y t·ªça ƒë·ªô ƒë·∫ßu ti√™n (n·∫øu c√≥ nhi·ªÅu)

            # L·∫•y k√≠ch th∆∞·ªõc ·∫£nh
            h, w, _ = img_last.shape

            # C·∫Øt v√πng tr√™n v√† d∆∞·ªõi c·ªßa ch·ªØ k√Ω
            top_region = img_last[0:y1, 0:w]
            bottom_region = img_last[y2:h, x1:x2]

            # Nh·∫≠n di·ªán vƒÉn b·∫£n t·ª´ hai v√πng
            top_text = self.ocr.ocr(top_region)[0]
            bottom_text = self.ocr.ocr(bottom_region)[0]

            # L·ªçc k·∫øt qu·∫£ nh·∫≠n di·ªán
            top_result = [
                line[1][0]
                for line in (top_text or [])  # N·∫øu None th√¨ chuy·ªÉn th√†nh list r·ªóng
                if line and len(line) > 1 and line[1] and len(line[1]) > 0
            ]

            bottom_result = [
                line[1][0]
                for line in (bottom_text or [])  # N·∫øu None th√¨ chuy·ªÉn th√†nh list r·ªóng
                if line and len(line) > 1 and line[1] and len(line[1]) > 0
            ]

            # G·ªôp k·∫øt qu·∫£ t·ª´ c·∫£ hai v√πng
            extracted_text = top_result + bottom_result
        else:
            extracted_text = []
        df_title = pd.DataFrame(extracted_text)
        return df_title, extracted_text

    def normalize_text(self, text):
        return unidecode(str(text)).lower().strip()

    def recognize_financial_table(self, df, financial_tables, threshold=80):
        """
        Nh·∫≠n di·ªán ti√™u ƒë·ªÅ b·∫£ng t√†i ch√≠nh t·ª´ m·ªôt DataFrame.

        Args:
            df (pd.DataFrame): DataFrame ch·ª©a d·ªØ li·ªáu c·∫ßn ki·ªÉm tra.
            financial_tables (list): Danh s√°ch c√°c b·∫£ng t√†i ch√≠nh chu·∫©n.
            image : ·∫¢nh ƒëang x√©t
            threshold (int): Ng∆∞·ª°ng ƒë·ªô t∆∞∆°ng ƒë·ªìng t·ªëi thi·ªÉu ƒë·ªÉ ch·∫•p nh·∫≠n.
        Returns:
            tuple: (T√™n b·∫£ng t√†i ch√≠nh nh·∫≠n di·ªán ƒë∆∞·ª£c, ·∫£nh t∆∞∆°ng ·ª©ng)
        """
        # Chu·∫©n h√≥a danh s√°ch b·∫£ng t√†i ch√≠nh
        normalized_tables = [self.normalize_text(table) for table in financial_tables]

        # Duy·ªát qua t·ª´ng c·ªôt trong DataFrame
        for column in df.columns:
            for value in df[column].dropna():  # B·ªè qua gi√° tr·ªã NaN
                norm_value = self.normalize_text(value)

                # Ki·ªÉm tra kh·ªõp ch√≠nh x√°c tr∆∞·ªõc
                if norm_value in normalized_tables:
                    print(f"‚úÖ Kh·ªõp ch√≠nh x√°c: {value} (c·ªôt: {column})")
                    recognized_title = financial_tables[normalized_tables.index(norm_value)]
                    return recognized_title

                # N·∫øu kh√¥ng kh·ªõp ch√≠nh x√°c, ki·ªÉm tra ƒë·ªô t∆∞∆°ng ƒë·ªìng
                for norm_table in normalized_tables:
                    similarity = fuzz.partial_ratio(norm_value, norm_table)
                    if similarity >= threshold:
                        print(
                            f"üîπ Kh·ªõp t∆∞∆°ng ƒë·ªìng ({similarity}%): {value} ~ {norm_table} (c·ªôt: {column})"
                        )
                        recognized_title = financial_tables[
                            normalized_tables.index(norm_table)
                        ]
                        return recognized_title

        print("‚ùå Kh√¥ng t√¨m th·∫•y b·∫£ng t√†i ch√≠nh n√†o ph√π h·ª£p.")
        return None

    def get_model_params(self, model):
        if model == "gemini-2.0-flash":
            return 1, 0.95, 64
        return None
